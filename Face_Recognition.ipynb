{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AliButtar/Cognyne/blob/main/Face_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBUwsDJlj3gN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0e9547b-499e-43bf-81d8-29035837059b"
      },
      "source": [
        "# Most Recent One (Suggested)\r\n",
        "!pip install git+https://github.com/rcmalli/keras-vggface.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/rcmalli/keras-vggface.git\n",
            "  Cloning https://github.com/rcmalli/keras-vggface.git to /tmp/pip-req-build-6r5vsjmh\n",
            "  Running command git clone -q https://github.com/rcmalli/keras-vggface.git /tmp/pip-req-build-6r5vsjmh\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.19.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (2.10.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (7.0.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (2.4.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (3.13)\n",
            "Building wheels for collected packages: keras-vggface\n",
            "  Building wheel for keras-vggface (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-vggface: filename=keras_vggface-0.6-cp36-none-any.whl size=8310 sha256=ba75563554a71784b159367db190033b12ed79b6f88c42bf53c5ab363e393e37\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tx905vo9/wheels/36/07/46/06c25ce8e9cd396dabe151ea1d8a2bc28dafcb11321c1f3a6d\n",
            "Successfully built keras-vggface\n",
            "Installing collected packages: keras-vggface\n",
            "Successfully installed keras-vggface-0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTzUzSFYTC7q",
        "outputId": "c2037a64-b0ff-47e3-ea41-4661fab04b79"
      },
      "source": [
        "!pip show keras-vggface"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: keras-vggface\n",
            "Version: 0.6\n",
            "Summary: VGGFace implementation with Keras framework\n",
            "Home-page: https://github.com/rcmalli/keras-vggface\n",
            "Author: Refik Can MALLI\n",
            "Author-email: mallir@itu.edu.tr\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: numpy, keras, pyyaml, pillow, six, scipy, h5py\n",
            "Required-by: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jc5wmHIbFwtG",
        "outputId": "43da0bff-3c2f-4a16-d5e0-569d0cc0b74e"
      },
      "source": [
        "!pip install keras_applications"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras_applications\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\r\u001b[K     |██████▌                         | 10kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20kB 14.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 30kB 13.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 40kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 3.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras_applications) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras_applications) (1.19.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras_applications) (1.15.0)\n",
            "Installing collected packages: keras-applications\n",
            "Successfully installed keras-applications-1.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elnxepoOUIc8",
        "outputId": "8b82dea7-04b4-4461-ea02-dcef58a87a3f"
      },
      "source": [
        "import keras_vggface\r\n",
        "# print version\r\n",
        "print(keras_vggface.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5mVLfJEF7Pt",
        "outputId": "a239d10a-47d9-4acd-a82a-203ae4abaf27"
      },
      "source": [
        "pip install mtcnn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mtcnn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/43/abee91792797c609c1bf30f1112117f7a87a713ebaa6ec5201d5555a73ef/mtcnn-0.1.0-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from mtcnn) (4.1.2.30)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from mtcnn) (2.4.3)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.19.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras>=2.0.0->mtcnn) (1.15.0)\n",
            "Installing collected packages: mtcnn\n",
            "Successfully installed mtcnn-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AYZ0srC1yFT"
      },
      "source": [
        "from matplotlib import pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "from PIL import Image\r\n",
        "from numpy import asarray\r\n",
        "from scipy.spatial.distance import cosine\r\n",
        "from mtcnn.mtcnn import MTCNN\r\n",
        "from keras_vggface.vggface import VGGFace\r\n",
        "from keras_vggface.utils import preprocess_input\r\n",
        "import numpy as np\r\n",
        "import cv2\r\n",
        "import csv\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTBjwvh511Gr"
      },
      "source": [
        "# extract a single face from a given photograph\r\n",
        "def extract_face(pixels, required_size=(224, 224)):\r\n",
        "    # create the detector, using default weights\r\n",
        "    detector = MTCNN()\r\n",
        "    # detect faces in the image\r\n",
        "    results = detector.detect_faces(pixels)\r\n",
        "    print(results)\r\n",
        "    # extract the bounding box from the first face\r\n",
        "    x1, y1, width, height = results[0]['box']\r\n",
        "    x2, y2 = x1 + width, y1 + height\r\n",
        "    # extract the face\r\n",
        "    face = pixels[y1:y2, x1:x2]\r\n",
        "    # resize pixels to the model size\r\n",
        "    image = Image.fromarray(face)\r\n",
        "    image = image.resize(required_size)\r\n",
        "    face_array = asarray(image)\r\n",
        "    \r\n",
        "    return face_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-cvEBaZ11EL"
      },
      "source": [
        "# extract faces and calculate face embeddings for a list of photo files\r\n",
        "def get_embeddings(img):\r\n",
        "    # extract faces\r\n",
        "    face = [extract_face(f) for f in img]\r\n",
        "    \r\n",
        "    print(face)\r\n",
        "    \r\n",
        "    # convert into an array of samples\r\n",
        "    sample = asarray(face, 'float32')\r\n",
        "    \r\n",
        "    # prepare the face for the model, e.g. center pixels\r\n",
        "    samples = preprocess_input(sample, version=2)\r\n",
        "    \r\n",
        "    # create a vggface model\r\n",
        "    model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\r\n",
        "    \r\n",
        "    # perform prediction\r\n",
        "    yhat = model.predict(sample)\r\n",
        "\r\n",
        "    return yhat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq-9t-9h11B5"
      },
      "source": [
        "# determine if a candidate face is a match for a known face\r\n",
        "def is_match(known_embedding, candidate_embedding, thresh=0.5):\r\n",
        "    \r\n",
        "    # calculate distance between embeddings\r\n",
        "    score = cosine(known_embedding, candidate_embedding)\r\n",
        "    if score <= thresh:\r\n",
        "        return True\r\n",
        "    else:\r\n",
        "        return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NnXpNU24XHg"
      },
      "source": [
        "from IPython.display import display, Javascript\r\n",
        "from google.colab.output import eval_js\r\n",
        "from base64 import b64decode\r\n",
        "\r\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\r\n",
        "  js = Javascript('''\r\n",
        "    async function takePhoto(quality) {\r\n",
        "      const div = document.createElement('div');\r\n",
        "      const capture = document.createElement('button');\r\n",
        "      capture.textContent = 'Capture';\r\n",
        "      div.appendChild(capture);\r\n",
        "\r\n",
        "      const video = document.createElement('video');\r\n",
        "      video.style.display = 'block';\r\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\r\n",
        "\r\n",
        "      document.body.appendChild(div);\r\n",
        "      div.appendChild(video);\r\n",
        "      video.srcObject = stream;\r\n",
        "      await video.play();\r\n",
        "\r\n",
        "      // Resize the output to fit the video element.\r\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\r\n",
        "\r\n",
        "      // Wait for Capture to be clicked.\r\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\r\n",
        "\r\n",
        "      const canvas = document.createElement('canvas');\r\n",
        "      canvas.width = video.videoWidth;\r\n",
        "      canvas.height = video.videoHeight;\r\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\r\n",
        "      stream.getVideoTracks()[0].stop();\r\n",
        "      div.remove();\r\n",
        "      return canvas.toDataURL('image/jpeg', quality);\r\n",
        "    }\r\n",
        "    ''')\r\n",
        "  display(js)\r\n",
        "  data = eval_js('takePhoto({})'.format(quality))\r\n",
        "  binary = b64decode(data.split(',')[1])\r\n",
        "  with open(filename, 'wb') as f:\r\n",
        "    f.write(binary)\r\n",
        "  return filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxGv6HY2-kGx"
      },
      "source": [
        "def run_webcam():\r\n",
        "  take_photo()\r\n",
        "\r\n",
        "  frame = cv2.imread('photo.jpg')\r\n",
        "  \r\n",
        "  img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\r\n",
        "  \r\n",
        "  e = get_embeddings([img])\r\n",
        "  \r\n",
        "  return e, frame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM7h9oRveZ8t"
      },
      "source": [
        "# df = pd.DataFrame(columns=['Name','Position', 'ID', 'Password', \"Embeddings\"])\r\n",
        "# df.to_csv('user.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOs-AzLO10_O"
      },
      "source": [
        "def signup():\r\n",
        "    \r\n",
        "    e, frame = run_webcam()\r\n",
        "    \r\n",
        "    df = pd.read_csv(\"user.csv\") \r\n",
        "        \r\n",
        "    \r\n",
        "    have_account = False \r\n",
        "    for arr in df['Embeddings']:\r\n",
        "        arr = [float(x) for x in arr[1:-1].split(',')]\r\n",
        "        if(is_match(arr, e[0])):\r\n",
        "            have_account = True\r\n",
        "                         \r\n",
        "    if (have_account):\r\n",
        "        print(\"You already have an account.\")\r\n",
        "        signin(frame, e, True)\r\n",
        "        \r\n",
        "    else:\r\n",
        "        name = input(\"Enter your Name: \")\r\n",
        "        position = input(\"Enter your Position: \")\r\n",
        "        userId = input(\"Enter you Registration number or Employee id: \")\r\n",
        "        password = input(\"Enter you Password: \")\r\n",
        "        \r\n",
        "        \r\n",
        "        df = df.append({'Name': name,'Position': position, 'ID': userId, 'Password': password}, ignore_index=True)\r\n",
        "        df.at[df.shape[0]-1, 'Embeddings'] = [emb for emb in e[0]]\r\n",
        "        \r\n",
        "        df.to_csv('user.csv', index = False)\r\n",
        "            \r\n",
        "        print(\"You have signed up!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaVfR8h0BYDj"
      },
      "source": [
        "def signin(frame = None, e = None, redirected = False):\r\n",
        "\r\n",
        "    global NAME\r\n",
        "    global ID\r\n",
        "    global E\r\n",
        "\r\n",
        "    if(not (redirected)):\r\n",
        "        e, frame = run_webcam()\r\n",
        "\r\n",
        "    E=e\r\n",
        "\r\n",
        "    df = pd.read_csv(\"user.csv\") \r\n",
        "\r\n",
        "    index = -1\r\n",
        "    i = 0\r\n",
        "    for arr in df['Embeddings']:\r\n",
        "        arr = [float(x) for x in arr[1:-1].split(',')]\r\n",
        "        if(is_match(arr, e)):\r\n",
        "            index = i\r\n",
        "            break\r\n",
        "        i = i+1\r\n",
        "\r\n",
        "    if (index != -1):\r\n",
        "        user_info = df.loc[index]\r\n",
        "        NAME = user_info['Name'] \r\n",
        "        ID = user_info['ID']\r\n",
        "        print(\"Successfully signed in\")\r\n",
        "        # Write some text on the frame.\r\n",
        "        cv2.putText(frame, \"Name \" + user_info['Name'], (10,30),\r\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 3)\r\n",
        "\r\n",
        "        # Write some more text on the frame at different location.\r\n",
        "        cv2.putText(frame, \"ID: \"+ str(user_info['ID']), (10, 60),\r\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 3)\r\n",
        "\r\n",
        "        cv2_imshow(frame)\r\n",
        "\r\n",
        "    else:\r\n",
        "        print(\"You donot have an account\")\r\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tJVqHsg1066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "204ed652-337c-4ade-bcc3-3f4b7827c2d8"
      },
      "source": [
        "signup()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8f6cdcba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8f6cdcba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8f6cdcba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[{'box': [225, 138, 109, 137], 'confidence': 0.9998643398284912, 'keypoints': {'left_eye': (269, 182), 'right_eye': (318, 196), 'nose': (297, 205), 'mouth_left': (261, 234), 'mouth_right': (308, 245)}}]\n",
            "[array([[[236, 237, 221],\n",
            "        [236, 237, 221],\n",
            "        [237, 236, 221],\n",
            "        ...,\n",
            "        [237, 237, 225],\n",
            "        [238, 238, 226],\n",
            "        [238, 238, 226]],\n",
            "\n",
            "       [[236, 237, 221],\n",
            "        [236, 237, 221],\n",
            "        [237, 236, 221],\n",
            "        ...,\n",
            "        [237, 237, 225],\n",
            "        [238, 238, 226],\n",
            "        [237, 237, 225]],\n",
            "\n",
            "       [[236, 237, 221],\n",
            "        [236, 237, 221],\n",
            "        [237, 236, 221],\n",
            "        ...,\n",
            "        [236, 236, 224],\n",
            "        [237, 237, 225],\n",
            "        [237, 237, 225]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[222, 225, 216],\n",
            "        [222, 225, 216],\n",
            "        [224, 224, 214],\n",
            "        ...,\n",
            "        [ 32,  35,  40],\n",
            "        [ 30,  33,  38],\n",
            "        [ 29,  32,  37]],\n",
            "\n",
            "       [[221, 225, 216],\n",
            "        [224, 227, 218],\n",
            "        [233, 234, 224],\n",
            "        ...,\n",
            "        [ 29,  32,  37],\n",
            "        [ 29,  32,  37],\n",
            "        [ 28,  31,  36]],\n",
            "\n",
            "       [[220, 224, 215],\n",
            "        [225, 228, 219],\n",
            "        [238, 239, 229],\n",
            "        ...,\n",
            "        [ 28,  31,  36],\n",
            "        [ 28,  31,  36],\n",
            "        [ 28,  31,  36]]], dtype=uint8)]\n",
            "Enter your Name: Muhammad Ali\n",
            "Enter your Position: Student\n",
            "Enter you Registration number or Employee id: 075\n",
            "Enter you Password: 1234\n",
            "You have signed up!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu-_60QXBfzB"
      },
      "source": [
        "signin()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAcl-o9KDUJY",
        "outputId": "5210bdb3-90d1-4355-c726-47e8392b40e4"
      },
      "source": [
        "NAME, ID, E"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Muhammad Ali Buttar',\n",
              " 75,\n",
              " array([[0.        , 2.13911   , 1.133177  , ..., 0.        , 0.01169913,\n",
              "         0.00977477]], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KBM_YtFrgfX"
      },
      "source": [
        "# test = pd.DataFrame(columns=[\"Class_name\", \"Embeddings\"])\r\n",
        "# test.to_csv('class.csv')\r\n",
        "# df = pd.DataFrame(columns=[\"Students_Names\",'Students_ID'])\r\n",
        "# df.to_csv('ML-01.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbsm0HTnNFPw"
      },
      "source": [
        "def create_class():\r\n",
        "    df = pd.read_csv(\"class.csv\", index_col = 0) \r\n",
        "\r\n",
        "    class_name = input('Enter the name of your Class: ')\r\n",
        "\r\n",
        "    count = df.shape[0]\r\n",
        "    \r\n",
        "    df.at[count, 'Class_name'] = class_name\r\n",
        "    df.at[count, 'Embeddings'] = [emb for emb in E[0]]\r\n",
        "\r\n",
        "    df.to_csv('class.csv')\r\n",
        "\r\n",
        "    print(\"Class created successfully!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLRvbl1eEzzJ",
        "outputId": "1896ffce-cb43-4fc7-82da-4c9a10567998"
      },
      "source": [
        "create_class()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the name of your Class: ML4\n",
            "Class created successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbYLM_gYE4cM"
      },
      "source": [
        "def join_class(class_name):\r\n",
        "\r\n",
        "    print('Show Teacher Face')\r\n",
        "\r\n",
        "    e, _ = run_webcam()\r\n",
        "\r\n",
        "    df = pd.read_csv(\"class.csv\", index_col = 0) \r\n",
        "\r\n",
        "    index = -1\r\n",
        "    i = 0\r\n",
        "    for cl in df['Class_name']:\r\n",
        "        if ( cl == class_name ):\r\n",
        "            index = i\r\n",
        "            break\r\n",
        "        i = i+1\r\n",
        "\r\n",
        "    if (index != -1):\r\n",
        "        em = df['Embeddings'][index]\r\n",
        "        em = [float(x) for x in em[1:-1].split(',')]\r\n",
        "        if (is_match(e, em)):\r\n",
        "            print(\"Show your own face.\")\r\n",
        "            e2, _ = run_webcam()\r\n",
        "\r\n",
        "            if (is_match(e2, E)):\r\n",
        "\r\n",
        "                if not os.path.exists(class_name+'.csv'):\r\n",
        "                  \r\n",
        "                  df_class = pd.DataFrame(columns=[\"Students_Names\",'Students_ID'])\r\n",
        "                  df_class.to_csv(class_name+'.csv')\r\n",
        "\r\n",
        "                class_df = pd.read_csv(class_name + \".csv\", index_col = 0) \r\n",
        "                class_df = class_df.append({'Students_Names': NAME, 'Students_ID': ID}, ignore_index=True)\r\n",
        "                class_df.to_csv(class_name + \".csv\")\r\n",
        "                print(class_name + \" Class Joined\")\r\n",
        "\r\n",
        "            else:\r\n",
        "                print(\"Signin with your own account.\")\r\n",
        "        \r\n",
        "        else:\r\n",
        "            print(\"Incorrect Teacher!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "afAtvS1q0Lz0",
        "outputId": "452e6541-84da-4516-ad99-813d2c49b881"
      },
      "source": [
        "df = pd.read_csv('class.csv', index_col=0)\r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class_name</th>\n",
              "      <th>Embeddings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BSSE-7C</td>\n",
              "      <td>[0.0, 0.20406674, 2.698341, 2.2890139, 1.00103...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ML-01</td>\n",
              "      <td>[0.0, 0.20406674, 2.698341, 2.2890139, 1.00103...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ML</td>\n",
              "      <td>[0.0, 2.13911, 1.133177, 9.5343275, 0.4623918,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ML2</td>\n",
              "      <td>[0.0, 2.13911, 1.133177, 9.5343275, 0.4623918,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ML3</td>\n",
              "      <td>[0.0, 1.3310406, 2.0747457, 11.555553, 2.74519...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ML4</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.34843898, 0.0, 0.0, 0.0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Class_name                                         Embeddings\n",
              "0    BSSE-7C  [0.0, 0.20406674, 2.698341, 2.2890139, 1.00103...\n",
              "1      ML-01  [0.0, 0.20406674, 2.698341, 2.2890139, 1.00103...\n",
              "2         ML  [0.0, 2.13911, 1.133177, 9.5343275, 0.4623918,...\n",
              "3        ML2  [0.0, 2.13911, 1.133177, 9.5343275, 0.4623918,...\n",
              "4        ML3  [0.0, 1.3310406, 2.0747457, 11.555553, 2.74519...\n",
              "5        ML4  [0.0, 0.0, 0.0, 0.0, 0.34843898, 0.0, 0.0, 0.0..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiLga90ouHw3"
      },
      "source": [
        "join_class(\"ML-01\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiYEpVMoWg5y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}